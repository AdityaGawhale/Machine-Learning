{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the message data into 'df' DataFrame, label columns (The given dataset here doesn't exist anymore so replace it with any other dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_table(\"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\",header=None)\n",
    "names=['label','messages']\n",
    "df.columns=names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split the message data using sklearn\n",
    "\n",
    "X_train gives Training message data on which algorithm is trained on (excludes output or 'label' column)\n",
    "\n",
    "X_test gives Testing message data on which algorithm is tested on (excludes output or 'label' column)\n",
    "\n",
    "y_train gives 'label' column or output column for prediction derived from training data\n",
    "\n",
    "y_train gives 'label' column or output column to be checked for prediction derived from testing data and calculate accuracy of algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['messages'], df['label'], test_size=0.30)\n",
    "XTrain=X_train.reset_index(drop=True)\n",
    "YTrain=y_train.reset_index(drop=True)\n",
    "XTest=X_test.reset_index(drop=True)\n",
    "YTest=y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorizer is called, Firstly the number of columns are decided based on number of disitnct words in the given data. \n",
    "Each row corresponds to a given message sentence and each column value will be the number of occurences of that distinct word (column name) in that sentence. This is all handled by CountVectorizer. \n",
    " \n",
    "CountVectorizer is internal to Jupyter Notebook, no need to import anything\n",
    "\n",
    "The parameter to initialize CountVectorizer needs to be changed since it does not recognize single words like 'a' as distinct words. For this ' token_pattern=r\"(?u)\\b\\w\\w+\\b\" ' which is a default parameter is updated to ' token_pattern=r\"(?u)\\b\\w+\\b\" ' which recognizes single words \n",
    "\n",
    "The vectorized data is converted to arrays for each message sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv=CountVectorizer(stop_words=None, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "x=cv.fit_transform(XTrain)\n",
    "a2=x.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from CountVectorizer a2 is sent to new DataFrame for training data which would be numerical now (no. of occurences of a distinct word in given sentence corresponding to a row) \n",
    "\n",
    "Column names are obtained from get_feature_names() function of CountVectorizer that gives names of distinct words\n",
    "\n",
    "Output column appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTRAIN=pd.DataFrame(a2, columns =cv.get_feature_names())\n",
    "dfTRAIN['Output']=YTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list1 contains column names of our training data (distinct words)\n",
    "\n",
    "list0 contains different distinct values of output i.e spam and ham\n",
    "\n",
    "Probability of <<'word'|'output value'>> has:\n",
    "Numerator=(Total no. of occurences 'word' in sentences which are classified as given 'output value') + 1\n",
    "\n",
    "Denomenator=(Total no. of occurences of all words in sentences which are classified as given 'output value') + (no. of distinct words in sentences which are classified as given 'output value')\n",
    "\n",
    "P('word'|'output value')=Numerator/Denomenator\n",
    "\n",
    "list2 has Total no. of occurences of all words in sentences which are classified as given 'output value'\n",
    "\n",
    "Dict2 has keys 'wordOutput_value' and values as P(word|Output_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num=0\n",
    "\n",
    "Dict1={}\n",
    "Dict2={}\n",
    "\n",
    "list1=dfTRAIN.columns\n",
    "list0=dfTRAIN['Output'].value_counts().index\n",
    "\n",
    "for i in range(0,len(list0)):\n",
    "    for j in range(0,(len(list1)-1)):\n",
    "        Num=dfTRAIN[dfTRAIN['Output']==list0[i]][list1[j]].sum()\n",
    "        list2=dfTRAIN[dfTRAIN['Output']==list0[i]].sum()#Returns a series\n",
    "        list2=list2.drop(labels=['Output'])\n",
    "\n",
    "        Prob=(Num+1)/(list2.sum()+len(list2[list2>0]))\n",
    "\n",
    "        print(\"P(Text=\",list1[j],\"|\",\"Output=\",list0[i],\")=\",Prob)\n",
    "        \n",
    "        Dict2[list1[j]+list0[i]]=Prob\n",
    "        \n",
    "print(Dict2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=pd.DataFrame(XTest, columns='Text')\n",
    "Test['Class']=YTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list3 is getting sidtinct words from each sentence of 'Test' data\n",
    "\n",
    "list0 contains different distinct values of output i.e spam and ham\n",
    "\n",
    "colnames are distinct words\n",
    "\n",
    "Probability of a sentence in Test data having a certain 'Output Value' is calculated by multiplying each of their distinct words probabilities in given sentence for given 'Output Value'. These probabilities are fetched from Dict2 Dictionary.\n",
    "\n",
    "This is compares with Probability of same sentence having another 'Output Value' in same way\n",
    "\n",
    "All these probabilities of same sentence having different Output values is compared. Highest probability Output value for sentence gives classification of that sentence (meaning it has that Ouput value). This prediction is compared with Output Values of Test data to get final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "\n",
    "for k in range(0,Test.shape[0]):\n",
    "    list3=(Test['Text'][k]).split(\" \")\n",
    "    colnames=list(dfTRAIN.columns)\n",
    "    print(list3)\n",
    "\n",
    "    Mul=1\n",
    "    Greatest=0\n",
    "    Greatest_Output='yo'\n",
    "\n",
    "    for i in range(0,len(list0)):\n",
    "        Mul=1\n",
    "        for j in range(0,len(list3)):\n",
    "            try:\n",
    "                a=colnames.index(list3[j])\n",
    "            except ValueError:\n",
    "                print(list3[j])\n",
    "                continue\n",
    "            \n",
    "            print(\"Dict:\",Dict2[list3[j]+list0[i]])\n",
    "            Mul=Dict2[list3[j]+list0[i]]*Mul\n",
    "            print(Mul)\n",
    "        Mul=Mul*(dfTRAIN[dfTRAIN['Output']==list0[i]].shape[0])/(dfTRAIN.shape[0])\n",
    "      \n",
    "            \n",
    "        if(Mul>Greatest):\n",
    "            Greatest=Mul\n",
    "            print(Greatest)\n",
    "            Greatest_Output=list0[i]\n",
    "        \n",
    "    print(Test['Text'][k],\"is classified as:\",Greatest_Output)\n",
    "    if(Greatest_Output==Test['Class'][k]):\n",
    "        count=count+1\n",
    "\n",
    "print(\"Accuracy:\",(count/Test.shape[0])) \n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
